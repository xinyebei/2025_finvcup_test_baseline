# log dir
log_dir: /data/

# model setting
pretrained: /data/weights/pretrained/xception-b5690688.pth
model_name: xception # model name
backbone_name: xception # backbone name
finetune: true

#backbone setting
backbone_config:
  mode: original
  num_classes: 2
  inc: 3
  dropout: false

# dataset
all_dataset: [train, test1]
train_dataset: [train]

test_dataset: [test1]

compression: c23 # compression-level for videos
train_batchSize: 32 # training batch size
test_batchSize: 64 # test batch size
workers: 4 # number of data loading workers
frame_num: { "train": 32, "test": 32 } # number of frames to use per video in training and testing
resolution: 256 # resolution of output image to network
with_mask: false # whether to include mask information in the input
with_landmark: false # whether to include facial landmark information in the input

# data augmentation
use_data_augmentation: true # Add this flag to enable/disable data augmentation
data_aug:
  flip_prob: 0.5
  rotate_prob: 0.5
  rotate_limit: [-10, 10]
  blur_prob: 0.5
  blur_limit: [3, 7]
  brightness_prob: 0.5
  brightness_limit: [-0.1, 0.1]
  contrast_limit: [-0.1, 0.1]
  quality_lower: 40
  quality_upper: 100

# mean and std for normalization
mean: [0.5, 0.5, 0.5]
std: [0.5, 0.5, 0.5]

# optimizer config
optimizer:
  # choose between 'adam' and 'sgd'
  type: adam
  adam:
    lr: 0.000005 # learning rate
    beta1: 0.9 # beta1 for Adam optimizer
    beta2: 0.999 # beta2 for Adam optimizer
    eps: 0.00000001 # epsilon for Adam optimizer
    weight_decay: 0.0005 # weight decay for regularization
    amsgrad: false
  sgd:
    lr: 0.000002 # learning rate 2e-6
    momentum: 0.9 # momentum for SGD optimizer
    weight_decay: 0.0005 # weight decay for regularization

# training config

lr_scheduler: step # learning rate scheduler
lr_step: 2
lr_gamma: 0.9
# lr_scheduler: null # learning rate schedule
nEpochs: 10 # number of epochs to train for
start_epoch: 0 # manual epoch number (useful for restarts)
save_epoch: 1 # interval epochs for saving models
rec_iter: 100 # interval iterations for recording
logdir: ./logs # folder to output images and logs
manualSeed: 1024 # manual seed for random number generation
save_ckpt: true # whether to save checkpoint
save_feat: true # whether to save features

# loss function
loss_func: cross_entropy # loss function to use
# loss_func: focal_loss # loss function to use
losstype: null

# metric
metric_scoring: auc # metric for evaluation (auc, acc, eer, ap)

# cuda

cuda: true # whether to use CUDA acceleration
cudnn: true # whether to use CuDNN for convolution operations
